{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNuMCOV9Pe1+J0TCOC8RKPL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sadyk703/Practical_RL_1/blob/master/DDPG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import gym\n",
        "from collections import deque\n",
        "import random\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s69kKyCbnDWL",
        "outputId": "9f5f1e39-43f7-4cdf-82d0-d82f02c76aa6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define actor network\n",
        "class Actor(nn.Module):\n",
        "    def __init__(self, state_dim, action_dim, hidden_size=256):\n",
        "        super(Actor, self).__init__()\n",
        "        self.fc1 = nn.Linear(state_dim, hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.fc3 = nn.Linear(hidden_size, action_dim)\n",
        "\n",
        "    def forward(self, state):\n",
        "        x = torch.relu(self.fc1(state))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = torch.tanh(self.fc3(x))\n",
        "        return x\n",
        "\n",
        "# Define critic network\n",
        "class Critic(nn.Module):\n",
        "    def __init__(self, state_dim, action_dim, hidden_size=256):\n",
        "        super(Critic, self).__init__()\n",
        "        self.fc1 = nn.Linear(state_dim + action_dim, hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.fc3 = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    def forward(self, state, action):\n",
        "        x = torch.cat([state, action], dim=1)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Ornstein-Uhlenbeck process for exploration noise\n",
        "class OrnsteinUhlenbeckProcess:\n",
        "    def __init__(self, size, mu=0., theta=0.15, sigma=0.2):\n",
        "        self.size = size\n",
        "        self.mu = mu\n",
        "        self.theta = theta\n",
        "        self.sigma = sigma\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.state = np.ones(self.size) * self.mu\n",
        "\n",
        "    def sample(self):\n",
        "        x = self.state\n",
        "        dx = self.theta * (self.mu - x) + self.sigma * np.random.randn(len(x))\n",
        "        self.state = x + dx\n",
        "        return self.state\n",
        "\n",
        "# Define DDPG agent\n",
        "class DDPGAgent:\n",
        "    def __init__(self, state_dim, action_dim, lr_actor=1e-4, lr_critic=1e-3, gamma=0.99, tau=0.001):\n",
        "        self.actor = Actor(state_dim, action_dim)\n",
        "        self.actor_target = Actor(state_dim, action_dim)\n",
        "        self.actor_optimizer = optim.Adam(self.actor.parameters(), lr=lr_actor)\n",
        "        self.critic = Critic(state_dim, action_dim)\n",
        "        self.critic_target = Critic(state_dim, action_dim)\n",
        "        self.critic_optimizer = optim.Adam(self.critic.parameters(), lr=lr_critic)\n",
        "        self.gamma = gamma\n",
        "        self.tau = tau\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        self.update_target_networks(tau=1.0)\n",
        "\n",
        "        self.noise = OrnsteinUhlenbeckProcess(action_dim)\n",
        "\n",
        "    def select_action(self, state, noise=True):\n",
        "        state = torch.FloatTensor(state).unsqueeze(0).to(self.device)\n",
        "        action = self.actor(state).cpu().detach().numpy().squeeze(0)\n",
        "        if noise:\n",
        "            action += self.noise.sample()\n",
        "        return np.clip(action, -1.0, 1.0)\n",
        "\n",
        "    def update(self, replay_buffer, batch_size):\n",
        "        state_batch, action_batch, reward_batch, next_state_batch, done_batch = replay_buffer.sample(batch_size)\n",
        "\n",
        "        state_batch = torch.FloatTensor(state_batch).to(self.device)\n",
        "        action_batch = torch.FloatTensor(action_batch).to(self.device)\n",
        "        reward_batch = torch.FloatTensor(reward_batch).unsqueeze(1).to(self.device)\n",
        "        next_state_batch = torch.FloatTensor(next_state_batch).to(self.device)\n",
        "        done_batch = torch.FloatTensor(done_batch).unsqueeze(1).to(self.device)\n",
        "\n",
        "        next_action = self.actor_target(next_state_batch)\n",
        "        q_target_next = self.critic_target(next_state_batch, next_action)\n",
        "        q_target = reward_batch + self.gamma * (1 - done_batch) * q_target_next\n",
        "\n",
        "        q = self.critic(state_batch, action_batch)\n",
        "        critic_loss = nn.functional.mse_loss(q, q_target)\n",
        "\n",
        "        self.critic_optimizer.zero_grad()\n",
        "        critic_loss.backward()\n",
        "        self.critic_optimizer.step()\n",
        "\n",
        "        policy_loss = -self.critic(state_batch, self.actor(state_batch)).mean()\n",
        "\n",
        "        self.actor_optimizer.zero_grad()\n",
        "        policy_loss.backward()\n",
        "        self.actor_optimizer.step()\n",
        "\n",
        "        self.update_target_networks()\n",
        "\n",
        "    def update_target_networks(self, tau=None):\n",
        "        if tau is None:\n",
        "            tau = self.tau\n",
        "        for target_param, param in zip(self.actor_target.parameters(), self.actor.parameters()):\n",
        "            target_param.data.copy_(tau * param.data + (1 - tau) * target_param.data)\n",
        "        for target_param, param in zip(self.critic_target.parameters(), self.critic.parameters()):\n",
        "            target_param.data.copy_(tau * param.data + (1 - tau) * target_param.data)\n",
        "\n",
        "# Define a replay buffer\n",
        "class ReplayBuffer:\n",
        "    def __init__(self, capacity):\n",
        "        self.buffer = deque(maxlen=capacity)\n",
        "\n",
        "    def add(self, state, action, reward, next_state, done):\n",
        "        self.buffer.append((state, action, reward, next_state, done))\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        batch = random.sample(self.buffer, batch_size)\n",
        "        state, action, reward, next_state, done = map(np.stack, zip(*batch))\n",
        "        return state, action, reward, next_state, done"
      ],
      "metadata": {
        "id": "y6aTZYU9nynz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize environment and parameters\n",
        "env = gym.make(\"Pendulum-v1\")\n",
        "state_dim = env.observation_space.shape[0]\n",
        "action_dim = env.action_space.shape[0]\n",
        "agent = DDPGAgent(state_dim, action_dim)\n",
        "\n",
        "# Initialize replay buffer\n",
        "replay_buffer = ReplayBuffer(capacity=1000000)\n",
        "\n",
        "# Training loop\n",
        "max_episodes = 100\n",
        "max_steps = 50\n",
        "batch_size = 128\n",
        "\n",
        "for episode in range(max_episodes):\n",
        "    state = env.reset()\n",
        "    agent.noise.reset()\n",
        "    episode_reward = 0\n",
        "    for step in range(max_steps):\n",
        "        action = agent.select_action(state, noise=True)\n",
        "        next_state, reward, done, _ = env.step(action)\n",
        "        replay_buffer.add(state, action, reward, next_state, done)\n",
        "        episode_reward += reward\n",
        "        state = next_state\n",
        "        if len(replay_buffer.buffer) > batch_size:\n",
        "            agent.update(replay_buffer, batch_size)\n",
        "        if done:\n",
        "            break\n",
        "    print(\"Episode: {}, Total Reward: {:.2f}\".format(episode, episode_reward))\n",
        "    plt.plot(episode_reward)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rzddVYWDnpQC",
        "outputId": "25d13f10-f265-496c-d623-a4eb8fd582ba"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:241: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
            "  if not isinstance(terminated, (bool, np.bool8)):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 0, Total Reward: -243.02\n",
            "Episode: 1, Total Reward: -242.25\n",
            "Episode: 2, Total Reward: -350.64\n",
            "Episode: 3, Total Reward: -237.94\n",
            "Episode: 4, Total Reward: -274.37\n",
            "Episode: 5, Total Reward: -413.88\n",
            "Episode: 6, Total Reward: -283.23\n",
            "Episode: 7, Total Reward: -292.07\n",
            "Episode: 8, Total Reward: -346.71\n",
            "Episode: 9, Total Reward: -319.44\n",
            "Episode: 10, Total Reward: -416.42\n",
            "Episode: 11, Total Reward: -389.95\n",
            "Episode: 12, Total Reward: -287.45\n",
            "Episode: 13, Total Reward: -254.54\n",
            "Episode: 14, Total Reward: -362.11\n",
            "Episode: 15, Total Reward: -244.02\n",
            "Episode: 16, Total Reward: -330.51\n",
            "Episode: 17, Total Reward: -258.50\n",
            "Episode: 18, Total Reward: -389.34\n",
            "Episode: 19, Total Reward: -317.17\n",
            "Episode: 20, Total Reward: -381.83\n",
            "Episode: 21, Total Reward: -254.86\n",
            "Episode: 22, Total Reward: -341.43\n",
            "Episode: 23, Total Reward: -328.36\n",
            "Episode: 24, Total Reward: -381.29\n",
            "Episode: 25, Total Reward: -305.73\n",
            "Episode: 26, Total Reward: -211.73\n",
            "Episode: 27, Total Reward: -358.32\n",
            "Episode: 28, Total Reward: -240.73\n",
            "Episode: 29, Total Reward: -219.80\n",
            "Episode: 30, Total Reward: -243.94\n",
            "Episode: 31, Total Reward: -336.67\n",
            "Episode: 32, Total Reward: -410.76\n",
            "Episode: 33, Total Reward: -414.17\n",
            "Episode: 34, Total Reward: -375.52\n",
            "Episode: 35, Total Reward: -358.67\n",
            "Episode: 36, Total Reward: -405.33\n",
            "Episode: 37, Total Reward: -435.18\n",
            "Episode: 38, Total Reward: -380.56\n",
            "Episode: 39, Total Reward: -374.47\n",
            "Episode: 40, Total Reward: -364.46\n",
            "Episode: 41, Total Reward: -262.87\n",
            "Episode: 42, Total Reward: -296.69\n",
            "Episode: 43, Total Reward: -330.72\n",
            "Episode: 44, Total Reward: -263.62\n",
            "Episode: 45, Total Reward: -320.92\n",
            "Episode: 46, Total Reward: -340.29\n",
            "Episode: 47, Total Reward: -335.12\n",
            "Episode: 48, Total Reward: -431.75\n",
            "Episode: 49, Total Reward: -244.65\n",
            "Episode: 50, Total Reward: -432.61\n",
            "Episode: 51, Total Reward: -233.12\n",
            "Episode: 52, Total Reward: -304.28\n",
            "Episode: 53, Total Reward: -281.61\n",
            "Episode: 54, Total Reward: -340.24\n",
            "Episode: 55, Total Reward: -323.19\n",
            "Episode: 56, Total Reward: -377.93\n",
            "Episode: 57, Total Reward: -238.01\n",
            "Episode: 58, Total Reward: -407.63\n",
            "Episode: 59, Total Reward: -430.66\n",
            "Episode: 60, Total Reward: -430.70\n",
            "Episode: 61, Total Reward: -261.13\n",
            "Episode: 62, Total Reward: -296.04\n",
            "Episode: 63, Total Reward: -240.05\n",
            "Episode: 64, Total Reward: -314.47\n",
            "Episode: 65, Total Reward: -439.24\n",
            "Episode: 66, Total Reward: -311.51\n",
            "Episode: 67, Total Reward: -235.43\n",
            "Episode: 68, Total Reward: -376.20\n",
            "Episode: 69, Total Reward: -348.42\n",
            "Episode: 70, Total Reward: -428.86\n",
            "Episode: 71, Total Reward: -306.98\n",
            "Episode: 72, Total Reward: -131.47\n",
            "Episode: 73, Total Reward: -320.54\n",
            "Episode: 74, Total Reward: -401.02\n",
            "Episode: 75, Total Reward: -230.64\n",
            "Episode: 76, Total Reward: -277.82\n",
            "Episode: 77, Total Reward: -425.39\n",
            "Episode: 78, Total Reward: -387.90\n",
            "Episode: 79, Total Reward: -372.54\n",
            "Episode: 80, Total Reward: -274.05\n",
            "Episode: 81, Total Reward: -370.42\n",
            "Episode: 82, Total Reward: -255.15\n",
            "Episode: 83, Total Reward: -259.68\n",
            "Episode: 84, Total Reward: -390.75\n",
            "Episode: 85, Total Reward: -285.73\n",
            "Episode: 86, Total Reward: -315.88\n",
            "Episode: 87, Total Reward: -350.07\n",
            "Episode: 88, Total Reward: -325.96\n",
            "Episode: 89, Total Reward: -326.24\n",
            "Episode: 90, Total Reward: -233.79\n",
            "Episode: 91, Total Reward: -416.86\n",
            "Episode: 92, Total Reward: -400.27\n",
            "Episode: 93, Total Reward: -358.91\n",
            "Episode: 94, Total Reward: -274.01\n",
            "Episode: 95, Total Reward: -279.53\n",
            "Episode: 96, Total Reward: -410.87\n",
            "Episode: 97, Total Reward: -282.36\n",
            "Episode: 98, Total Reward: -239.08\n",
            "Episode: 99, Total Reward: -269.85\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YG40LVhL4M35"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}